#!/usr/bin/env bash

# if nodemanager is running, exit
systemctl status nodemanager
if [ $? -ne 0 ] ; then

  mem_yarn=$(grep -C 1 '>yarn.nodemanager.resource.memory-mb<' <%= node['hops']['conf_dir'] %>/yarn-site.xml | grep value | sed 's/<value>//' | sed 's/<\/value>//' | tr -d '[:space:]')
  mem_found=$(free -m | grep Mem | awk '{ print $2 }')
  cpus_yarn=$(grep -C 1 '>yarn.nodemanager.resource.cpu-vcores<' <%= node['hops']['conf_dir'] %>/yarn-site.xml | grep value | sed 's/<value>//' | sed 's/<\/value>//' | tr -d '[:space:]')
  cpus_found=$(cat /proc/cpuinfo | grep -c "cpu cores")
  # make sure GPUs are available
#  which nvidia-smi
#  if [ $? -eq 0 ] ; then

    #
    # GPUs
    #
    gpus_found=$(lspci | grep -i 'nvidia' | wc -l)
    echo "nvidia-smi found $gpus_found GPUs"
    # how many gpus are configured in yarn-site.xml
    gpus_yarn=$(grep -C 2 '>yarn.nodemanager.resource.gpus<' <%= node['hops']['conf_dir'] %>/yarn-site.xml | grep value | sed 's/<value>//' | sed 's/<\/value>//' | tr -d '[:space:]')
    echo "yarn-site.xml had $gpus_yarn GPUs"    
    # if nvidia-smi and yarn-site.xml disagree on the number of GPUs, take number from nvidia-smi
    if [ "$gpus_found" != "$gpus_yarn" ] ; then
      # the nodemanager will recreate the correct number of cgroups. No cgroups should be running when this is executed
      rmdir /sys/fs/cgroup/devices/hops-yarn
      perl -i -p0e "s/yarn\.nodemanager\.resource\.gpus<\/name>.*<value>${gpus_yarn}/yarn\.nodemanager\.resource\.gpus<\/name>\n    <value>${gpus_found}/s" <%= node['hops']['conf_dir'] %>/yarn-site.xml
      echo "GPU configuration updated to the number of GPUs found by nvidia-smi: $gpus_found"
    else
      echo "GPU configuration looks good."
    fi

    #
    # CPUs
    #
    if [ "$cpus_found" != "$cpus_yarn" ] ; then
      perl -i -p0e "s/cpu-vcores.*<value>${cpus_yarn}/cpu-vcores<\/name>\n    <value>${cpus_found}/s" <%= node['hops']['conf_dir'] %>/yarn-site.xml
    fi
    #
    # Memory
    #
    if [ "$mem_found" != "$mem_yarn" ] ; then
      perl -i -p0e "s/resource\.memory-mb.*<value>${mem_yarn}/resource\.memory-mb<\/name>\n    <value>${mem_found}/s" <%= node['hops']['conf_dir'] %>/yarn-site.xml
    fi

    
#  else
#      echo "Could not find nvidia-smi program in the PATH"
#      exit 0
#  fi


  chown <%= node['hops']['yarn']['user'] %> <%= node['hops']['home'] %>/etc/hadoop/yarn-site.xml

  
else
    echo "Nodemanager is running. Cannot check gpu configuration if the nodemanager is running"
    exit 0
fi
exit 0
